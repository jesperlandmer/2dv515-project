{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-Of-Words Classifier\n",
    "\n",
    "Import necessary dependencies from scikit. Use [pandas](https://pandas.pydata.org/) for file extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fileName = 'wikipedia_300/wikipedia_300.csv'\n",
    "col = ['Text', 'Category']\n",
    "\n",
    "# Read the dataset and split text and category\n",
    "df = pd.read_csv(fileName, header=0, sep=',', names=col)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Category'], random_state = 0, test_size=0.2)\n",
    "\n",
    "# Init the countvectorizer and convert the text/documents to a matrix of token counts\n",
    "# I.e create a bag of words\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Multinominal Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Games']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB_model = MultinomialNB().fit(X_train_counts, y_train)\n",
    "\n",
    "# Check if model is able to predict\n",
    "print(NB_model.predict(count_vect.transform([\"Script for games are good with java \"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Programming']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "SVM_model = LinearSVC().fit(X_train_counts, y_train)\n",
    "\n",
    "# Check if model is able to predict\n",
    "print(SVM_model.predict(count_vect.transform([\"Script for programs are good with java\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Accuracy\n",
    "\n",
    "Here we are comparing the accuracy score between the Naive Bayes method and the SVM method. We can see that the SVM has a higher accuracy score than the Naive Bayes method on classifing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/====== Multinominal Naive Bayes Classifier ======/\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Games       0.93      0.90      0.91        29\n",
      " Programming       0.91      0.94      0.92        31\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        60\n",
      "   macro avg       0.92      0.92      0.92        60\n",
      "weighted avg       0.92      0.92      0.92        60\n",
      "\n",
      "Accuracy Score: 91.67%\n",
      "Confusion Matrix:\n",
      "[[26  3]\n",
      " [ 2 29]]\n",
      "KFold(n_splits=10, random_state=None, shuffle=False)\n",
      "\n",
      "\n",
      "/====== Support Vector Machine Classifier ======/\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Games       0.96      0.90      0.93        29\n",
      " Programming       0.91      0.97      0.94        31\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        60\n",
      "   macro avg       0.94      0.93      0.93        60\n",
      "weighted avg       0.94      0.93      0.93        60\n",
      "\n",
      "Accuracy Score: 93.33%\n",
      "Confusion Matrix:\n",
      "[[26  3]\n",
      " [ 1 30]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "NB_predictions = NB_model.predict(X_test_counts)\n",
    "SVM_predictions = SVM_model.predict(X_test_counts)\n",
    "\n",
    "print('/====== Multinominal Naive Bayes Classifier ======/')\n",
    "print(classification_report(y_test, NB_predictions))\n",
    "print(f'Accuracy Score: {round(accuracy_score(y_test, NB_predictions) * 100, 2)}%')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, NB_predictions))\n",
    "print(k_fold)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('/====== Support Vector Machine Classifier ======/')\n",
    "print(classification_report(y_test, SVM_predictions))\n",
    "print(f'Accuracy Score: {round(accuracy_score(y_test, SVM_predictions) * 100, 2)}%')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, SVM_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Accuracy using Cross Validation\n",
    "\n",
    "By measuring the accuracy using cross validation, we get a completely different score. Here we are splitting the text documents into 10 folds (i.e. 10 groups), and checking the accuracy score for each fold. By measuring the mean accuracy score, we can see that the Naive Bayes method has a higher accuracy than SVM, but also has a higher spectrum of values.\n",
    "\n",
    "I'm assuming this is because the generative Naive Bayes model is better at handling smaller datasets, and the discriminative SVM doesn't get enough data to train on when folding the data 10 times. Maybe this has something to do with Naive Bayes handling overfitting better on this particular dataset using the default parameters.\n",
    "\n",
    "Or perhaps this has something to do with SVM getting p(x|y) while naive bayes are getting p(x,y).\n",
    "\n",
    "Or, as is probably my best assumption, I'm guessing in general this has to do with if the independence in naive bayes is more satisfied by the variables of this dataset by using cross validation, and the degree of class overlapping is smaller on the smaller sets, then the naive bayes method could outperform the svm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/====== Multinominal Naive Bayes Classifier ======/\n",
      "[0.96666667 0.96666667 0.9        0.96666667 0.93333333 1.\n",
      " 0.9        0.96666667 1.         0.93333333]\n",
      "Accuracy mean: 95.33% (+/- 6.8%)\n",
      "\n",
      "/====== Support Vector Machine Classifier ======/\n",
      "[0.93333333 0.93333333 0.9        0.93333333 0.86666667 0.9\n",
      " 0.93333333 0.93333333 0.93333333 0.9       ]\n",
      "Accuracy mean: 91.67% (+/- 4.47%)\n"
     ]
    }
   ],
   "source": [
    "X_data_counts = count_vect.transform(df['Text'])\n",
    "\n",
    "print('/====== Multinominal Naive Bayes Classifier ======/')\n",
    "scores = cross_val_score(NB_model, X_data_counts, df['Category'], cv=10)\n",
    "print(scores)\n",
    "print(f'Accuracy mean: {round(scores.mean()*100, 2)}% (+/- {round(scores.std()*2*100, 2)}%)')\n",
    "\n",
    "print()\n",
    "print('/====== Support Vector Machine Classifier ======/')\n",
    "scores = cross_val_score(SVM_model, X_data_counts, df['Category'], cv=10)\n",
    "print(scores)\n",
    "print(f'Accuracy mean: {round(scores.mean()*100, 2)}% (+/- {round(scores.std()*2*100, 2)}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TF-IDF Converter\n",
    "\n",
    "One problem with just using counter is that longer documents will have a higher count average than shorter documents even if they might be on the same topic, and this might create discrepancies.\n",
    "\n",
    "By using TF (Term Frequencies) we can avoid this problem by checking words frequencies compared to the total number of words. Adding IDF (Inverse Document Frequency) also down-weights words that occur frequently in many documents and are therefore less informative (e.g. and, if, then).\n",
    "\n",
    "We'll first transform the train-data to a tf-dif representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and then re-iniate the classification models with the new tf-dif representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_model = MultinomialNB().fit(X_train_tf, y_train)\n",
    "SVM_model = LinearSVC().fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/====== Multinominal Naive Bayes Classifier ======/\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Games       1.00      0.93      0.96        29\n",
      " Programming       0.94      1.00      0.97        31\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        60\n",
      "   macro avg       0.97      0.97      0.97        60\n",
      "weighted avg       0.97      0.97      0.97        60\n",
      "\n",
      "Accuracy Score: 96.67%\n",
      "Confusion Matrix:\n",
      "[[27  2]\n",
      " [ 0 31]]\n",
      "\n",
      "\n",
      "/====== Support Vector Machine Classifier ======/\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Games       0.91      1.00      0.95        29\n",
      " Programming       1.00      0.90      0.95        31\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        60\n",
      "   macro avg       0.95      0.95      0.95        60\n",
      "weighted avg       0.95      0.95      0.95        60\n",
      "\n",
      "Accuracy Score: 95.0%\n",
      "Confusion Matrix:\n",
      "[[29  0]\n",
      " [ 3 28]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "\n",
    "NB_predictions = NB_model.predict(X_test_counts)\n",
    "SVM_predictions = SVM_model.predict(X_test_counts)\n",
    "\n",
    "print('/====== Multinominal Naive Bayes Classifier ======/')\n",
    "print(classification_report(y_test, NB_predictions))\n",
    "print(f'Accuracy Score: {round(accuracy_score(y_test, NB_predictions) * 100, 2)}%')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, NB_predictions))\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('/====== Support Vector Machine Classifier ======/')\n",
    "print(classification_report(y_test, SVM_predictions))\n",
    "print(f'Accuracy Score: {round(accuracy_score(y_test, SVM_predictions) * 100, 2)}%')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, SVM_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Accuracy using Cross Validation\n",
    "\n",
    "When adding the text frequencies weights and downgrading frequently occuring words, the SVM outperforms the Naive Bayes classifier. The Naive bayes classifier even got worse adding these methods on cross validation. Maybe the transformed dataset weighing words disrupt the independence validation of naive bayes on small datasets, while improving SVM classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/====== Multinominal Naive Bayes Classifier ======/\n",
      "[0.93333333 0.96666667 0.86666667 0.96666667 0.86666667 1.\n",
      " 0.93333333 0.9        0.9        0.93333333]\n",
      "Accuracy mean: 92.67% (+/- 8.33%)\n",
      "\n",
      "/====== Support Vector Machine Classifier ======/\n",
      "[0.96666667 1.         0.9        0.93333333 0.9        0.96666667\n",
      " 0.96666667 0.96666667 0.96666667 0.93333333]\n",
      "Accuracy mean: 95.0% (+/- 6.15%)\n"
     ]
    }
   ],
   "source": [
    "X_data_counts = count_vect.transform(df['Text'])\n",
    "tf = TfidfTransformer(use_idf=False).fit(X_data_counts)\n",
    "X_data_tf = tf.transform(X_data_counts)\n",
    "\n",
    "print('/====== Multinominal Naive Bayes Classifier ======/')\n",
    "scores = cross_val_score(NB_model, X_data_tf, df['Category'], cv=10)\n",
    "print(scores)\n",
    "print(f'Accuracy mean: {round(scores.mean()*100, 2)}% (+/- {round(scores.std()*2*100, 2)}%)')\n",
    "\n",
    "print()\n",
    "print('/====== Support Vector Machine Classifier ======/')\n",
    "scores = cross_val_score(SVM_model, X_data_tf, df['Category'], cv=10)\n",
    "print(scores)\n",
    "print(f'Accuracy mean: {round(scores.mean()*100, 2)}% (+/- {round(scores.std()*2*100, 2)}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
