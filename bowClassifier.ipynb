{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-Of-Words Classifier\n",
    "\n",
    "Import necessary dependencies from scikit. Use [pandas](https://pandas.pydata.org/) for file extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fileName = 'wikipedia_300/wikipedia_300.csv'\n",
    "col = ['Text', 'Category']\n",
    "\n",
    "# Read the dataset and split text and category\n",
    "df = pd.read_csv(fileName, header=0, sep=',', names=col)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Category'], random_state = 0, test_size=0.2)\n",
    "\n",
    "# Init the countvectorizer and convert the text/documents to a matrix of token counts\n",
    "# I.e create a bag of words\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Multinominal Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Games']\n"
     ]
    }
   ],
   "source": [
    "NB_model = MultinomialNB().fit(X_train_counts, y_train)\n",
    "\n",
    "# Check if model is able to predict\n",
    "print(NB_model.predict(count_vect.transform([\"Script for games are good with java \"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Games']\n"
     ]
    }
   ],
   "source": [
    "SVM_model = LinearSVC().fit(X_train_counts, y_train)\n",
    "\n",
    "# Check if model is able to predict\n",
    "print(SVM_model.predict(count_vect.transform([\"Script for games are good with java\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Accuracy\n",
    "\n",
    "Here we are comparing the accuracy score between the Naive Bayes method and the SVM method. We can see that the SVM has a higher accuracy score than the Naive Bayes method on classifing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/====== Multinominal Naive Bayes Classifier ======/\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Games       0.93      0.90      0.91        29\n",
      " Programming       0.91      0.94      0.92        31\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        60\n",
      "   macro avg       0.92      0.92      0.92        60\n",
      "weighted avg       0.92      0.92      0.92        60\n",
      "\n",
      "Accuracy Score: 91.67%\n",
      "Confusion Matrix:\n",
      "[[26  3]\n",
      " [ 2 29]]\n",
      "KFold(n_splits=10, random_state=None, shuffle=False)\n",
      "\n",
      "\n",
      "/====== Support Vector Machine Classifier ======/\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Games       0.96      0.90      0.93        29\n",
      " Programming       0.91      0.97      0.94        31\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        60\n",
      "   macro avg       0.94      0.93      0.93        60\n",
      "weighted avg       0.94      0.93      0.93        60\n",
      "\n",
      "Accuracy Score: 93.33%\n",
      "Confusion Matrix:\n",
      "[[26  3]\n",
      " [ 1 30]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "NB_predictions = NB_model.predict(X_test_counts)\n",
    "SVM_predictions = SVM_model.predict(X_test_counts)\n",
    "\n",
    "print('/====== Multinominal Naive Bayes Classifier ======/')\n",
    "print(classification_report(y_test, NB_predictions))\n",
    "print(f'Accuracy Score: {round(accuracy_score(y_test, NB_predictions) * 100, 2)}%')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, NB_predictions))\n",
    "print(k_fold)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('/====== Support Vector Machine Classifier ======/')\n",
    "print(classification_report(y_test, SVM_predictions))\n",
    "print(f'Accuracy Score: {round(accuracy_score(y_test, SVM_predictions) * 100, 2)}%')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, SVM_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Accuracy using Cross Validation\n",
    "\n",
    "By measuring the accuracy using cross validation, we get a completely different score. Here we are splitting the text documents into 10 folds (i.e. 10 groups), and checking the accuracy score for each fold. By measuring the mean accuracy score, we can see that the Naive Bayes method has a higher accuracy than SVM, but also has a higher spectrum of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/====== Multinominal Naive Bayes Classifier ======/\n",
      "[0.96666667 0.96666667 0.9        0.96666667 0.93333333 1.\n",
      " 0.9        0.96666667 1.         0.93333333]\n",
      "Accuracy mean: 95.33% (+/- 6.8%)\n",
      "\n",
      "/====== Support Vector Machine Classifier ======/\n",
      "[0.93333333 0.93333333 0.9        0.93333333 0.86666667 0.9\n",
      " 0.93333333 0.93333333 0.93333333 0.9       ]\n",
      "Accuracy mean: 91.67% (+/- 4.47%)\n"
     ]
    }
   ],
   "source": [
    "print('/====== Multinominal Naive Bayes Classifier ======/')\n",
    "scores = cross_val_score(NB_model, count_vect.transform(df['Text']), df['Category'], cv=10)\n",
    "print(scores)\n",
    "print(f'Accuracy mean: {round(scores.mean()*100, 2)}% (+/- {round(scores.std()*2*100, 2)}%)')\n",
    "\n",
    "print()\n",
    "print('/====== Support Vector Machine Classifier ======/')\n",
    "scores = cross_val_score(SVM_model, count_vect.transform(df['Text']), df['Category'], cv=10)\n",
    "print(scores)\n",
    "print(f'Accuracy mean: {round(scores.mean()*100, 2)}% (+/- {round(scores.std()*2*100, 2)}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TF-IDF Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
